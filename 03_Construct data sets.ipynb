{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NetworkGen import *\n",
    "from GurobiSolver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directories\n",
    "data = \"Train\"\n",
    "network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "models_dir = os.path.join(parent_dir, \"Models-gp\", data)\n",
    "opt_0_dir = os.path.join(models_dir, \"Model_0\")\n",
    "data_dir = os.path.join(parent_dir, \"Data\")\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize columns and collections\n",
    "cols = [\"id\", \"k\", \"arc\", \"tail_in_degree\", \"tail_out_degree\", \"head_in_degree\", \"head_out_degree\", \"d_s\", \"d_t\", \"C_r\", \"F_r\"]\n",
    "vals = []\n",
    "# Iterate over the train networks\n",
    "for f in tqdm(os.listdir(network_dir)):\n",
    "    name, ext = f.split('.')\n",
    "    G = load_network(f\"{network_dir}/{name}\")\n",
    "    # Get max flow\n",
    "    opt_0 = load_json(name, opt_0_dir)[\"ObjVal\"]\n",
    "    # Initialize collections\n",
    "    z_bar = {} # arcs that have been interdicted so far and their corresponding objective function value\n",
    "    # Create the basic model\n",
    "    m = create_model(G, name, B=1, unit_cost=True)\n",
    "    for i in range(G.number_of_edges()):\n",
    "        # Update and solve the model\n",
    "        m.update()\n",
    "        m.optimize()\n",
    "        # Break the loop if the objective function value is the same as the max flow (no more arcs to interdict while minimizing the maximum flow)\n",
    "        if m.ObjVal == opt_0:\n",
    "            break\n",
    "        # Get the interdicted arc\n",
    "        for var in m.getVars():\n",
    "            if \"z\" in var.VarName and var.x > 0:\n",
    "                (u,v) = tuple(var.VarName[2:-1].split(','))\n",
    "                # Add the arc to the collection of interdicted arcs\n",
    "                z_bar[(u,v)] = m.ObjVal\n",
    "                # Add the interdiction constraint\n",
    "                m.addConstr(m.getVarByName(f\"z[{u},{v}]\") == 0)\n",
    "                break\n",
    "    # Construct the labeled train set\n",
    "    id, k = name.split('_')[1:]\n",
    "    N = list(G.nodes())\n",
    "    sink_level = G.nodes[N[-1]][\"subset\"]\n",
    "    c = nx.get_edge_attributes(G, 'c')\n",
    "    c_max = max(c.values())\n",
    "    for u,v in G.edges:\n",
    "        in_degree_u = G.in_degree(u) if u != N[0] else 1\n",
    "        out_degree_v = G.out_degree(v) if v != N[-1] else 1\n",
    "        d_s = G.nodes[u][\"subset\"]/sink_level # tail distance from the source / number of levels\n",
    "        d_t = (sink_level - G.nodes[u][\"subset\"])/sink_level # tail distance from the sink / number of levels\n",
    "        # Reduction in the maximum flow\n",
    "        F_r = ((opt_0 - z_bar[(u,v)]) / opt_0) * 100 if (u,v) in z_bar else 0\n",
    "        # Append the values\n",
    "        vals.append([id, k, f\"({u},{v})\", in_degree_u, G.out_degree(u), G.in_degree(v), out_degree_v, d_s, d_t, c[(u, v)]/c_max, F_r])\n",
    "# Save the labeled train set\n",
    "df = pd.DataFrame(vals, columns=cols)\n",
    "df.to_csv(f\"{parent_dir}/Data/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directories\n",
    "data = \"Test\"\n",
    "network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "data_dir = os.path.join(parent_dir, \"Data\")\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:21<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize columns and collections\n",
    "cols = [\"id\", \"k\", \"arc\", \"tail_in_degree\", \"tail_out_degree\", \"head_in_degree\", \"head_out_degree\", \"d_s\", \"d_t\", \"C_r\"]\n",
    "vals = []\n",
    "# Iterate over the train networks\n",
    "for f in tqdm(os.listdir(network_dir)):\n",
    "    name, ext = f.split('.')\n",
    "    G = load_network(f\"{network_dir}/{name}\")\n",
    "    # Construct the labeled test set\n",
    "    id, k = name.split('_')[1:]\n",
    "    N = list(G.nodes())\n",
    "    sink_level = G.nodes[N[-1]][\"subset\"]\n",
    "    c = nx.get_edge_attributes(G, 'c')\n",
    "    c_max = max(c.values())\n",
    "    for u,v in G.edges:\n",
    "        in_degree_u = G.in_degree(u) if u != N[0] else 1\n",
    "        out_degree_v = G.out_degree(v) if v != N[-1] else 1\n",
    "        d_s = G.nodes[u][\"subset\"]/sink_level # tail distance from the source / number of levels\n",
    "        d_t = (sink_level - G.nodes[u][\"subset\"])/sink_level # tail distance from the sink / number of levels\n",
    "        # Append the values\n",
    "        vals.append([id, k, f\"({u},{v})\", in_degree_u, G.out_degree(u), G.in_degree(v), out_degree_v, d_s, d_t, c[(u, v)]/c_max])\n",
    "# Save the labeled train set\n",
    "df = pd.DataFrame(vals, columns=cols)\n",
    "df.to_csv(f\"{parent_dir}/Data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-gurobi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
