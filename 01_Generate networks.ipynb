{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NetworkGen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "os.makedirs(parent_dir + '/Results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directory to save network structures\n",
    "data = \"Train\"\n",
    "network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "os.makedirs(network_dir, exist_ok=True)\n",
    "# Desired network structures\n",
    "train_networks = {1: [5, 10, 25, 1],\n",
    "                  3: [8, 27, 50, 1]}\n",
    "replications = {1: 10, 3: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train networks\n",
    "for id, nNodes in tqdm(train_networks.items()):\n",
    "    for k in range(1, replications[id]+1):\n",
    "        G = hierarchical_network(nNodes, seed=10+k)\n",
    "        # Add edge attributes\n",
    "        random.seed(10+k)\n",
    "        c_u = 20\n",
    "        for u,v in G.edges:\n",
    "            G[u][v][\"c\"] = random.randint(1, 20)\n",
    "            G[u][v][\"b\"] = 1\n",
    "        save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 98.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save the networks details\n",
    "cols = [\"id\", \"k\", \"|N|\", \"|A|\", \"Level 0\", \"Level 1\", \"Level 2\", \"Level 3\", \"Level 4\"]\n",
    "vals = []\n",
    "for f in tqdm(os.listdir(network_dir)):\n",
    "    name, ext = f.split('.')\n",
    "    G = load_network(f\"{network_dir}/{name}\")\n",
    "    id, k = map(int, name.split('_')[1:])\n",
    "    n, m = G.number_of_nodes(), G.number_of_edges()\n",
    "    row = [id, k, n, m, 1]\n",
    "    row += train_networks[id]\n",
    "    vals.append(row)\n",
    "train_networks_df = pd.DataFrame(vals, columns=cols)\n",
    "train_networks_df = train_networks_df.sort_values(by=[\"id\", \"k\"])\n",
    "train_networks_df.to_csv(f\"Results/TrainNetworksDetails.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directory to save network structures\n",
    "data = \"Test\"\n",
    "network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "os.makedirs(network_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired network structures and number of replications\n",
    "small_networks_h = {1: [5, 10, 25, 1],\n",
    "                    3: [8, 27, 50, 1],\n",
    "                    5: [30, 100, 450, 1]}\n",
    "large_networks_h = {6: [1000, 1500, 1500, 2000, 2500, 2500, 3000, 5000, 10000, 1],\n",
    "                    7: [2500, 3000, 3000, 4500, 4500, 7000, 7000, 10000, 15000, 1],\n",
    "                    8: [2500, 3000, 3000, 4500, 4500, 7000, 7000, 10000, 15000, 1]}\n",
    "networks_nh = {2: [5, 10, 25, 40, 1],\n",
    "               4: [12, 50, 200, 410, 1]}\n",
    "replications = {1: 10, 3: 10, 5: 10, 6: 1, 7: 1, 8: 1, 2: 10, 4: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arc flow capacity and interdiction cost\n",
    "large_networks_c = {0: (50,100), 1: (1,75), 2: (1,50), 3: (1,40), 4: (1,40), 5: (1,30), 6: (1,30), 7: (1,20), 8: (1,20), 9: (50,100)}\n",
    "large_networks_b = {0: (100,101), 1: (1,75), 2: (1,50), 3: (1,40), 4: (1,40), 5: (1,30), 6: (1,30), 7: (1,20), 8: (1,20), 9: (100,101)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate small heierarchical networks\n",
    "for id, nNodes in tqdm(small_networks_h.items()):\n",
    "    for k in range(1, replications[id]+1):\n",
    "        G = hierarchical_network(nNodes, seed=k)\n",
    "        # Add edge attributes\n",
    "        random.seed(k)\n",
    "        if k <= 5:\n",
    "            c_u = 20\n",
    "        else:\n",
    "            c_u = 50\n",
    "        for u,v in G.edges:\n",
    "            G[u][v][\"c\"] = random.randint(1, c_u)\n",
    "            G[u][v][\"b\"] = random.randint(1, 50)\n",
    "        save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate large heierarchical networks\n",
    "for id, nNodes in tqdm(large_networks_h.items()):\n",
    "    for k in range(1, replications[id]+1):\n",
    "        G = hierarchical_network(nNodes, seed=k)# Add edge attributes\n",
    "        random.seed(k)\n",
    "        for u,v in G.edges:\n",
    "            u_level = G.nodes[u]['subset']\n",
    "            G[u][v][\"c\"] = random.randint(large_networks_c[u_level][0], large_networks_c[u_level][1])\n",
    "            G[u][v][\"b\"] = random.randint(large_networks_b[u_level][0], large_networks_b[u_level][1])\n",
    "        save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate large heierarchical networks\n",
    "for id, nNodes in tqdm(networks_nh.items()):\n",
    "    for k in range(1, replications[id]+1):\n",
    "        G = non_hierarchical_network(nNodes, seed=k)\n",
    "        # Add edge attributes\n",
    "        random.seed(k)\n",
    "        if k <= 5:\n",
    "            c_u = 20\n",
    "        else:\n",
    "            c_u = 50\n",
    "        for u,v in G.edges:\n",
    "            G[u][v][\"c\"] = random.randint(1, c_u)\n",
    "            G[u][v][\"b\"] = random.randint(1, 50)\n",
    "        save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split newtorks into small and large\n",
    "small_test_networks = {**small_networks_h, **networks_nh}\n",
    "large_test_networks = {**large_networks_h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:02<00:00, 19.62it/s] \n"
     ]
    }
   ],
   "source": [
    "# Save the small networks details\n",
    "cols = [\"id\", \"k\", \"|N|\", \"|A|\", \"Level 0\", \"Level 1\", \"Level 2\", \"Level 3\", \"Level 4\", \"Level 5\"]\n",
    "vals = []\n",
    "for f in tqdm(os.listdir(network_dir)):\n",
    "    name, ext = f.split('.')\n",
    "    id, k = map(int, name.split('_')[1:])\n",
    "    if id in small_test_networks:\n",
    "        G = load_network(f\"{network_dir}/{name}\")\n",
    "        n, m = G.number_of_nodes(), G.number_of_edges()\n",
    "        row = [id, k, n, m, 1]\n",
    "        row += small_test_networks[id]\n",
    "        if id % 2 != 0:\n",
    "            row += [0]\n",
    "        vals.append(row)\n",
    "small_test_networks_df = pd.DataFrame(vals, columns=cols).replace({0: '-'})\n",
    "small_test_networks_df = small_test_networks_df.sort_values(by=[\"id\", \"k\"])\n",
    "small_test_networks_df.to_csv(f\"Results/SmallTestNetworksDetails.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:24<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save the large networks details\n",
    "cols = [\"id\", \"k\", \"|N|\", \"|A|\", \"Level 0\", \"Level 1\", \"Level 2\", \"Level 3\", \"Level 4\", \"Level 5\", \"Level 6\", \"Level 7\", \"Level 8\", \"Level 9\", \"Level 10\"]\n",
    "vals = []\n",
    "for f in tqdm(os.listdir(network_dir)):\n",
    "    name, ext = f.split('.')\n",
    "    id, k = map(int, name.split('_')[1:])\n",
    "    if id in large_test_networks:\n",
    "        G = load_network(f\"{network_dir}/{name}\")\n",
    "        n, m = G.number_of_nodes(), G.number_of_edges()\n",
    "        row = [id, k, n, m]\n",
    "        # At each level we have [nNodes/c_range/b_range]\n",
    "        for i in range(10):\n",
    "            row.append(f\"[{large_test_networks[id][i]}/{large_networks_c[i]}/{large_networks_b[i]}]\")\n",
    "        row.append(f\"[{1}/-/-]\")\n",
    "        vals.append(row)\n",
    "large_test_networks_df = pd.DataFrame(vals, columns=cols)\n",
    "large_test_networks_df = large_test_networks_df.sort_values(by=[\"id\", \"k\"])\n",
    "large_test_networks_df.to_csv(f\"Results/LargeTestNetworksDetails.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-gurobi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
