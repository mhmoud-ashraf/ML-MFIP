{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NetworkGen import *\n",
    "from GurobiSolver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize directory to save network structures\n",
    "# data = \"Test\"\n",
    "# network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "# os.makedirs(network_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Desired network structures and number of replications\n",
    "# small_networks_h = {1: [5, 10, 25, 1],\n",
    "#                     3: [8, 27, 50, 1],\n",
    "#                     5: [30, 100, 450, 1]}\n",
    "# large_networks_h = {6: [1000, 1500, 1500, 2000, 2500, 2500, 3000, 5000, 10000, 1],\n",
    "#                     7: [2500, 3000, 3000, 4500, 4500, 7000, 7000, 10000, 15000, 1],\n",
    "#                     8: [2500, 3000, 3000, 4500, 4500, 7000, 7000, 10000, 15000, 1]}\n",
    "# networks_nh = {2: [5, 10, 25, 40, 1],\n",
    "#                4: [12, 50, 200, 410, 1]}\n",
    "# replications = {1: 10, 3: 10, 5: 10, 6: 1, 7: 1, 8: 1, 2: 10, 4: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arc flow capacity and interdiction cost\n",
    "# large_networks_c = {0: (50,100), 1: (1,75), 2: (1,50), 3: (1,40), 4: (1,40), 5: (1,30), 6: (1,30), 7: (1,20), 8: (1,20), 9: (50,100)}\n",
    "# large_networks_b = {0: (100,101), 1: (1,75), 2: (1,50), 3: (1,40), 4: (1,40), 5: (1,30), 6: (1,30), 7: (1,20), 8: (1,20), 9: (100,101)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate small heierarchical networks\n",
    "# for id, nNodes in tqdm(small_networks_h.items()):\n",
    "#     for k in range(1, replications[id]+1):\n",
    "#         G = hierarchical_network(nNodes, seed=k)\n",
    "#         # Add edge attributes\n",
    "#         random.seed(k)\n",
    "#         if k <= 5:\n",
    "#             c_u = 20\n",
    "#         else:\n",
    "#             c_u = 50\n",
    "#         for u,v in G.edges:\n",
    "#             G[u][v][\"c\"] = random.randint(1, c_u)\n",
    "#             G[u][v][\"b\"] = random.randint(1, 50)\n",
    "#         save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate large heierarchical networks\n",
    "# for id, nNodes in tqdm(large_networks_h.items()):\n",
    "#     for k in range(1, replications[id]+1):\n",
    "#         G = hierarchical_network(nNodes, seed=k)# Add edge attributes\n",
    "#         random.seed(k)\n",
    "#         for u,v in G.edges:\n",
    "#             u_level = G.nodes[u]['subset']\n",
    "#             G[u][v][\"c\"] = random.randint(large_networks_c[u_level][0], large_networks_c[u_level][1])\n",
    "#             G[u][v][\"b\"] = random.randint(large_networks_b[u_level][0], large_networks_b[u_level][1])\n",
    "#         save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate large heierarchical networks\n",
    "# for id, nNodes in tqdm(networks_nh.items()):\n",
    "#     for k in range(1, replications[id]+1):\n",
    "#         G = non_hierarchical_network(nNodes, seed=k)\n",
    "#         # Add edge attributes\n",
    "#         random.seed(k)\n",
    "#         if k <= 5:\n",
    "#             c_u = 20\n",
    "#         else:\n",
    "#             c_u = 50\n",
    "#         for u,v in G.edges:\n",
    "#             G[u][v][\"c\"] = random.randint(1, c_u)\n",
    "#             G[u][v][\"b\"] = random.randint(1, 50)\n",
    "#         save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize directory to save network structures\n",
    "# data = \"Train\"\n",
    "# network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "# os.makedirs(network_dir, exist_ok=True)\n",
    "# # Desired network structures\n",
    "# train_networks = {1: [5, 10, 25, 1],\n",
    "#                     3: [8, 27, 50, 1]}\n",
    "# replications = {1: 10, 3: 10}\n",
    "\n",
    "# for id, nNodes in tqdm(train_networks.items()):\n",
    "#     for k in range(1, replications[id]+1):\n",
    "#         G = hierarchical_network(nNodes, seed=10+k)\n",
    "#         # Add edge attributes\n",
    "#         random.seed(10+k)\n",
    "#         c_u = 20\n",
    "#         for u,v in G.edges:\n",
    "#             G[u][v][\"c\"] = random.randint(1, 20)\n",
    "#             G[u][v][\"b\"] = 1\n",
    "#         save_network_structure(G, f\"{network_dir}/network_{id}_{k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve networks to optimility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directories\n",
    "data = \"Test\"\n",
    "network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "models_dir = os.path.join(parent_dir, \"Models\", data)\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve test instances with B = 0 (equivalent to the max flow problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "unit_cost = False\n",
    "tag = \"\"\n",
    "B = 0 # if B = 0, the problem is equivalent to the max flow problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Solve instances\n",
    "# for f in tqdm(os.listdir(network_dir)):\n",
    "#     name, ext = f.split('.')\n",
    "#     G = nx.read_gexf(f\"{network_dir}/{name}.{ext}\")\n",
    "#     # Make directories\n",
    "#     model_dir = os.path.join(models_dir, f\"Model_{B}{tag}\")\n",
    "#     for format in [\"mps\", \"sol\", \"lp\", \"json\"]:\n",
    "#         os.makedirs(f\"{model_dir}/{format}\", exist_ok=True)\n",
    "#     # Solve the model\n",
    "#     m = solve_model(name, model_dir, B, unit_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc interdiction costs are greater that or equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_cost = False\n",
    "tag = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interdiction budget\n",
    "small_B = [5, 10, 20, 30, 40, 80, 120, 150, 200]\n",
    "large_B = [5, 100, 200, 500, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 15000, 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Solve instances\n",
    "# for f in tqdm(os.listdir(network_dir)):\n",
    "#     name, ext = f.split('.')\n",
    "#     G = nx.read_gexf(f\"{network_dir}/{name}.{ext}\")\n",
    "#     if name.split('_')[1] in map(str, [6, 7, 8]):\n",
    "#         B_vals = large_B\n",
    "#     else:\n",
    "#         B_vals = small_B\n",
    "#     for B in B_vals:\n",
    "#         # Make directories\n",
    "#         model_dir = os.path.join(models_dir, f\"Model_{B}{tag}\")\n",
    "#         for format in [\"mps\", \"sol\", \"lp\", \"json\"]:\n",
    "#             os.makedirs(f\"{model_dir}/{format}\", exist_ok=True)\n",
    "#         # Solve the model\n",
    "#         m = solve_model(name, model_dir, B, unit_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc interdiction costs are set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_cost = True\n",
    "tag = \"U\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interdiction budget\n",
    "small_uc_B = [i for i in range(1, 9+1)]\n",
    "large_uc_B = [1, 10, 50, 100, 500, 1000, 2000, 2500, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Solve instances\n",
    "# for f in tqdm(os.listdir(network_dir)):\n",
    "#     name, ext = f.split('.')\n",
    "#     G = nx.read_gexf(f\"{network_dir}/{name}.{ext}\")\n",
    "#     if name.split('_')[1] in map(str, [6, 7, 8]):\n",
    "#         B_vals = large_uc_B\n",
    "#     else:\n",
    "#         B_vals = small_uc_B\n",
    "#     for B in B_vals:\n",
    "#         # Make directories\n",
    "#         model_dir = os.path.join(models_dir, f\"Model_{B}{tag}\")\n",
    "#         for format in [\"mps\", \"sol\", \"lp\", \"json\"]:\n",
    "#             os.makedirs(f\"{model_dir}/{format}\", exist_ok=True)\n",
    "#         # Solve the model\n",
    "#         m = solve_model(name, model_dir, B, unit_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directories\n",
    "data = \"Train\"\n",
    "network_dir = os.path.join(parent_dir, \"Networks\", data)\n",
    "models_dir = os.path.join(parent_dir, \"Models\", data)\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve train instances with B = 0 (equivalent to the max flow problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "unit_cost = False\n",
    "tag = \"\"\n",
    "B = 0 # if B = 0, the problem is equivalent to the max flow problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Solve instances\n",
    "# for f in tqdm(os.listdir(network_dir)):\n",
    "#     name, ext = f.split('.')\n",
    "#     G = nx.read_gexf(f\"{network_dir}/{name}.{ext}\")\n",
    "#     # Make directories\n",
    "#     model_dir = os.path.join(models_dir, f\"Model_{B}{tag}\")\n",
    "#     for format in [\"mps\", \"sol\", \"lp\", \"json\"]:\n",
    "#         os.makedirs(f\"{model_dir}/{format}\", exist_ok=True)\n",
    "#     # Solve the model\n",
    "#     m = solve_model(name, model_dir, B, unit_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-gurobi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
